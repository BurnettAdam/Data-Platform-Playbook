"use strict";(self.webpackChunkdata_platform_playbook=self.webpackChunkdata_platform_playbook||[]).push([[2834],{3905:function(e,t,a){a.d(t,{Zo:function(){return d},kt:function(){return c}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,d=l(e,["components","mdxType","originalType","parentName"]),u=p(a),c=r,h=u["".concat(s,".").concat(c)]||u[c]||m[c]||o;return a?n.createElement(h,i(i({ref:t},d),{},{components:a})):n.createElement(h,i({ref:t},d))}));function c(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var p=2;p<o;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},9674:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return l},contentTitle:function(){return s},metadata:function(){return p},toc:function(){return d},default:function(){return u}});var n=a(7462),r=a(3366),o=(a(7294),a(3905)),i=["components"],l={title:"Ingesting data from databases into the Data Platform",description:"Ingesting database tables into the Data Platform using a JDBC Connection",layout:"playbook_js",tags:["playbook"]},s=void 0,p={unversionedId:"playbook/ingesting-data/database-ingestion",id:"playbook/ingesting-data/database-ingestion",isDocsHomePage:!1,title:"Ingesting data from databases into the Data Platform",description:"Ingesting database tables into the Data Platform using a JDBC Connection",source:"@site/docs/playbook/ingesting-data/005-database-ingestion.md",sourceDirName:"playbook/ingesting-data",slug:"/playbook/ingesting-data/database-ingestion",permalink:"/Data-Platform-Playbook/playbook/ingesting-data/database-ingestion",editUrl:"https://github.com/LBHackney-IT/data-platform-playbook/edit/master/docs/playbook/ingesting-data/005-database-ingestion.md",tags:[{label:"playbook",permalink:"/Data-Platform-Playbook/tags/playbook"}],version:"current",sidebarPosition:5,frontMatter:{title:"Ingesting data from databases into the Data Platform",description:"Ingesting database tables into the Data Platform using a JDBC Connection",layout:"playbook_js",tags:["playbook"]},sidebar:"docs",previous:{title:"Ingesting RDS snapshot into the Data Platform Landing Zone",permalink:"/Data-Platform-Playbook/playbook/ingesting-data/ingesting-rds-snapshot-in-landing-zone"},next:{title:"Guide to testing data quality in Glue Jobs",permalink:"/Data-Platform-Playbook/playbook/transforming-data/guides-to-testing-in-the-platform/data-quality-testing-guide"}},d=[{value:"Prerequisites",id:"prerequisites",children:[]},{value:"Overview",id:"overview",children:[{value:"Add the database credentials to the Data Platform project",id:"add-the-database-credentials-to-the-data-platform-project",children:[]},{value:"Construct the JDBC URL",id:"construct-the-jdbc-url",children:[]},{value:"Set up the Glue JDBC Connection",id:"set-up-the-glue-jdbc-connection",children:[]},{value:"Create a Glue job and Crawler",id:"create-a-glue-job-and-crawler",children:[]},{value:"Commit your changes and create a Pull Request for review by the Data Platform team",id:"commit-your-changes-and-create-a-pull-request-for-review-by-the-data-platform-team",children:[]},{value:"Running the ingestion manually",id:"running-the-ingestion-manually",children:[]},{value:"Example module block",id:"example-module-block",children:[]}]}],m={toc:d};function u(e){var t=e.components,a=(0,r.Z)(e,i);return(0,o.kt)("wrapper",(0,n.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"This guide explains the process of ingesting data/tables from databases into the Data Platform using AWS Glue JDBC Connection."),(0,o.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Check that your database type is supported by AWS Glue JDBC Connection (see ",(0,o.kt)("a",{parentName:"li",href:"https://docs.aws.amazon.com/glue/latest/dg/connection-defining.html"},"AWS Glue JDBC Connection Properties")," section) "),(0,o.kt)("li",{parentName:"ul"},"Ensure that your database allows user login/authentication, and you have a database user with login credentials",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"If you would like to restrict access to only a selection of tables in your database, then ensure the database's user permissions are updated to reflect this"),(0,o.kt)("li",{parentName:"ul"},"In addition to the database name and user login credentials, you will also need:",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"the type of database you want to connect to e.g. ",(0,o.kt)("inlineCode",{parentName:"li"},"mssql")),(0,o.kt)("li",{parentName:"ul"},"the database host name/ endpoint"),(0,o.kt)("li",{parentName:"ul"},"the database port number"))),(0,o.kt)("li",{parentName:"ul"},"These will be used to construct the ",(0,o.kt)("a",{parentName:"li",href:"#construct-the-jdbc-url"},"JDBC URL")," in a later section")))),(0,o.kt)("h2",{id:"overview"},"Overview"),(0,o.kt)("p",null,"In the following sections you will set up a connection from the Data Platform to your source database to ingest its data, which will involve:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Authenticating access to the source database from the Data Platform by adding the database credentials to AWS Secrets Manager"),(0,o.kt)("li",{parentName:"ul"},"Establishing a connection to the respective database by creating a Glue connection using a JDBC URL which uses the source database's credentials stored in Secrets Manager"),(0,o.kt)("li",{parentName:"ul"},"Populating a Glue Catalog database with the source database's table schemas and metadata by creating a Crawler and crawling the source database"),(0,o.kt)("li",{parentName:"ul"},"Pulling in the data from the source database and writing to the Data Platform S3 storage by creating a Glue job which uses the Glue connection as well as the table schemas and metadata from the Glue Catalog database   "),(0,o.kt)("li",{parentName:"ul"},"Making the data available for querying in Athena and other Glue jobs by creating a Crawler to crawl the tables in S3 which will then populate a predetermined Glue Catalog database")),(0,o.kt)("h3",{id:"add-the-database-credentials-to-the-data-platform-project"},"Add the database credentials to the Data Platform project"),(0,o.kt)("p",null,"The database credentials are retrieved from AWS Secrets Manager.\nThe credentials are used to allow the Data Platform to authenticate against the source database."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Contact a member of the Data Platform team to add the database credentials to Secrets Manager."),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"You will need to request that a ",(0,o.kt)("strong",{parentName:"p"},"secret")," (with an appropriate description) is created following the naming convention below: "),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"database-credentials/DATABASE_NAME-DATASET_NAME\n")),(0,o.kt)("p",{parentName:"li"},"e.g. ",(0,o.kt)("inlineCode",{parentName:"p"},"database-credentials/geolive-permits"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Request that the following key-value pairs be added to this secret:"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"database_name")," = ",(0,o.kt)("inlineCode",{parentName:"li"},'"Name of your database"')),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"username")," = ",(0,o.kt)("inlineCode",{parentName:"li"},'"Your database user username"')),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"password")," = ",(0,o.kt)("inlineCode",{parentName:"li"},'"Your database user password"'))))))),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Once the credentials have been added, you will be given a secret name which will be used to reference your stored credentials.\nMake a note of this as it will be needed in the ",(0,o.kt)("a",{parentName:"li",href:"#set-up-the-glue-jdbc-connection"},"Set up the Glue JDBC Connection section")," below.\n")),(0,o.kt)("h3",{id:"construct-the-jdbc-url"},"Construct the JDBC URL"),(0,o.kt)("p",null,"In this section, you will create the JDBC URL which will be used in the section below."),(0,o.kt)("p",null,"Generally JDBC URLs for different types of databases are quite similar.\nHowever, some differ slightly. You will be using the following to construct the JDBC URL:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"Database type"),(0,o.kt)("li",{parentName:"ul"},"Database name"),(0,o.kt)("li",{parentName:"ul"},"Database host/ endpoint e.g. ",(0,o.kt)("inlineCode",{parentName:"li"},"127.0.0.1")),(0,o.kt)("li",{parentName:"ul"},"Database port number e.g. ",(0,o.kt)("inlineCode",{parentName:"li"},"1433"))),(0,o.kt)("p",null,"Refer to ",(0,o.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/glue/latest/dg/connection-defining.html"},"AWS Glue JDBC Connection Properties")," for examples and guidance on how to construct your JDBC URL."),(0,o.kt)("h3",{id:"set-up-the-glue-jdbc-connection"},"Set up the Glue JDBC Connection"),(0,o.kt)("p",null,"Here you will configure a module which will set up the connection to the database, as well as a crawler to crawl the source database which will retrieve the\nmetadata and schemas of the database tables to populate in a Glue Catalog database."),(0,o.kt)("p",null,(0,o.kt)("em",{parentName:"p"},"For more technical details on the overall process, see: ",(0,o.kt)("a",{parentName:"em",href:"/Data-Platform-Playbook/spikes/mssql-ingestion"},"Database Ingestion documentation"))),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},"Open the ",(0,o.kt)("a",{parentName:"li",href:"https://github.com/LBHackney-IT/Data-Platform/tree/main/terraform"},"terraform directory")," in the Data Platform Project in GitHub.",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"If you don't have the correct permissions, you'll get a '404' error (see ",(0,o.kt)("a",{parentName:"li",href:"/Data-Platform-Playbook/playbook/getting-set-up/index"},"Getting Set Up on the Platform"),").")))),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Note: If the data you're ingesting is for a specific department then it should be ingested into that department's ",(0,o.kt)("inlineCode",{parentName:"strong"},"raw zone"),", otherwise it should go into the ",(0,o.kt)("inlineCode",{parentName:"strong"},"landing zone"))),(0,o.kt)("ol",null,(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Create a new file ",(0,o.kt)("inlineCode",{parentName:"p"},"29-<YOUR-DEPARTMENT-NAME>-<DATABASE-NAME>-database-ingestion.tf")," if department specific, otherwise ",(0,o.kt)("inlineCode",{parentName:"p"},"29-<DATABASE-NAME>-database-ingestion.tf")," "),(0,o.kt)("p",{parentName:"li"},"For example, for Academy (database), which is not department specific, the file name will be:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"29-academy-database-ingestion.tf\n")),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"Refer to this ",(0,o.kt)("a",{parentName:"em",href:"#example-module-block"},"example")," to get started.")))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Copy the ",(0,o.kt)("a",{parentName:"p",href:"#example-module-block"},"example module block")," paste it in your file.")),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Update the ",(0,o.kt)("inlineCode",{parentName:"p"},"module")," name using the following name convention: "),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"<department_name>_<database_name>_database_ingestion\n")),(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Note: the department name must be all lowercase and separated by underscores")),(0,o.kt)("p",{parentName:"li"}," For example: "),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},'"academy_lbhatestrbviews_database_ingestion"\n'))),(0,o.kt)("li",{parentName:"ol"},(0,o.kt)("p",{parentName:"li"},"Update or add your input variables."))),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("h4",{parentName:"li",id:"the-following-input-variables-are-required"},"The following input variables are required:"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"source")," (required): This will be ",(0,o.kt)("inlineCode",{parentName:"p"},'"../modules/database-ingestion-via-jdbc-connection"'),". It is the path to where the database ingestion module is saved within the repository"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},(0,o.kt)("strong",{parentName:"em"},"Note"),": If you've copied the example module block then you won\u2019t need to change the ",(0,o.kt)("strong",{parentName:"em"},"source")," variable")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"jdbc_connection_name")," (required): Name of the dataset that will be ingested. e.g. ",(0,o.kt)("inlineCode",{parentName:"p"},"Council Tax"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"jdbc_connection_url")," (required): This will be in the format: ",(0,o.kt)("inlineCode",{parentName:"p"},"jdbc:protocol://host:port/db_name")),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Set this to the JDBC URL you constructed in the previous section.\nYou can refer to ",(0,o.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/glue/latest/dg/connection-defining.html"},"AWS Glue JDBC Connection Properties")," for more guidance on how to construct your JDBC URL. "),(0,o.kt)("p",{parentName:"li"},"For example, a SQL Server database's JDBC URL will look like this: "),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},'jdbc_connection_url = "jdbc:sqlserver://10.120.23.22:1433;databaseName=LBHATestRBViews"\n'))))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"jdbc_connection_description")," (required): A description of the connection i.e. The type of connection, database and dataset that will be ingested\nFor example:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},'"JDBC connection to Academy Production Insights LBHATestRBViews database to ingest Council Tax data"\n'))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"jdbc_connection_subnet_id")," (required): The subnet to deploy the connection to.\nSet this to ",(0,o.kt)("inlineCode",{parentName:"p"},"local.subnet_ids_list[local.subnet_ids_random_index]"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"database_availability_zone")," (required): The availability zone to deploy the connection to.\nSet this to ",(0,o.kt)("inlineCode",{parentName:"p"},'"eu-west-2a"'))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"vpc_id")," (required): Set this to ",(0,o.kt)("inlineCode",{parentName:"p"},"data.aws_vpc.network.id"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"identifier_prefix")," (required): Set this to ",(0,o.kt)("inlineCode",{parentName:"p"},"local.short_identifier_prefix"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"database_secret_name")," (required): Name of the secret in AWS Secrets Manager where your database credentials are being stored.\nThis would have been shared with you by a member of the Data Platform team.\nFor example:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},'database_secret_name = "academy-database-credentials"\n')))))),(0,o.kt)("ol",{start:6},(0,o.kt)("li",{parentName:"ol"},"Commit your changes and create a Pull Request for review by the Data Platform team.\nYou should wait for it to be aprroved and deployed before moving onto the next step.",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"See ",(0,o.kt)("a",{parentName:"li",href:"../getting-set-up/using-github#committing-your-changes-to-the-data-platform-project"},"Committing changes")," section of the ",(0,o.kt)("strong",{parentName:"li"},"Using Github")," guide.\nThe Data Platform team needs to approve any changes to the code that you make, so your change won't happen automatically.")))),(0,o.kt)("h3",{id:"create-a-glue-job-and-crawler"},"Create a Glue job and Crawler"),(0,o.kt)("p",null,"Once your Pull Request for setting up the JDBC Connection has been approved and deployed, you can continue with this section."),(0,o.kt)("p",null,"Here you will create a Glue job which will use the JDBC connection you've just created to pull the database tables into S3.\nYou will also create a Crawler to read all the ingested tables from S3 and populate a Glue Catalog Database so that the\ndata can be queried in Athena or consumed by other Glue jobs for further processing."),(0,o.kt)("h4",{id:"create-a-glue-job-to-ingest-all-database-tables-to-s3"},"Create a Glue job to ingest all database tables to S3"),(0,o.kt)("p",null,"You can prototype your script and test ingesting a few tables by referring to an ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/ingest_database_tables_via_jdbc_connection.py"},"example script"),"\nand following the ",(0,o.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/using-glue-studio"},"Using Glue Studio")," guide.\nRefer to the ",(0,o.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/deploy-glue-jobs"},"Deploying Glue jobs to the Data Platform")," guide when you are ready to deploy your Glue job along with a Crawler\nwhich will read all the tables from S3 into a Glue Catalog Database where the tables can be queried."),(0,o.kt)("p",null,"The example script linked above will read all the tables and output them to a specified S3 location."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"It uses two helper functions which are imported from ",(0,o.kt)("inlineCode",{parentName:"li"},"helpers.py"),", these are: ",(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"get_all_database_tables"),": used to retrieve all the table names from the specified Glue Catalog Database"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"update_table_ingestion_details"),": used to create a dataframe containing stats, including errors, on the ingestion process for each table")))),(0,o.kt)("p",null,(0,o.kt)("strong",{parentName:"p"},"Set the input variables for the Glue job and Crawler using the ",(0,o.kt)("a",{parentName:"strong",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/deploy-glue-jobs"},"Glue job module"))),(0,o.kt)("p",null,"In addition to the variables and job parameters you'd normally set when ",(0,o.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/deploy-glue-jobs"},"deploying a Glue job"),", you need to set the following:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Input variables"),":"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"connections")," (required): The list of connections used for this job, i.e. JDBC connection.\nThis will be ",(0,o.kt)("inlineCode",{parentName:"p"},"[module.<NAME_OF_CONNECTION_MODULE>[0].jdbc_connection_name]"),".\nSee step 4 in the section: ",(0,o.kt)("a",{parentName:"p",href:"#set-up-the-glue-jdbc-connection"},"set up the glue JDBC connection")," above for a reminder of the module name."),(0,o.kt)("p",{parentName:"li"},"For example: "),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"[module.academy_lbhatestrbviews_database_ingestion[0].jdbc_connection_name]\n")),(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"Note: ensure there are surrounding square brackets (",(0,o.kt)("inlineCode",{parentName:"em"},"[]"),") around the value provided here"))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"schedule")," (Optional):\nIf you don't populate this variable then the Glue job and Crawler will run once on creation and after that you will be able to run the job manually\nin the AWS Console but, it won't run on a schedule. "),(0,o.kt)("p",{parentName:"li"},"If you want it to run on a schedule then please refer to the ",(0,o.kt)("strong",{parentName:"p"},'"Variables used for scheduling a Glue job"')," section of ",(0,o.kt)("a",{parentName:"p",href:"/Data-Platform-Playbook/playbook/transforming-data/using-aws-glue/deploy-glue-jobs#variables-used-for-scheduling-a-glue-job"},"this article")," for an explanation on how to set the variables to do so.\n")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"Job parameters"),":"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"Note: For the following optional ",(0,o.kt)("strong",{parentName:"p"},"job parameters"),"; ",(0,o.kt)("em",{parentName:"p"},'"--s3_ingestion_bucket_target"')," and ",(0,o.kt)("em",{parentName:"p"},'"--s3_ingestion_details_target"'),":"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("inlineCode",{parentName:"li"},"<ZONE>")," refers to either: ",(0,o.kt)("inlineCode",{parentName:"li"},"raw")," or ",(0,o.kt)("inlineCode",{parentName:"li"},"landing")," S3 zones"),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"If the data you're ingesting is for a specific department then it should be ingested into that department's ",(0,o.kt)("inlineCode",{parentName:"strong"},"raw")," zone, otherwise it should go into the ",(0,o.kt)("inlineCode",{parentName:"strong"},"landing")," zone")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},'"--source_catalog_database"')," (required): The Glue Catalog Database where your databases' table schemas are stored"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},"This will be ",(0,o.kt)("inlineCode",{parentName:"p"},"module.<NAME_OF_CONNECTION_MODULE>[0].ingestion_database_name"),"."),(0,o.kt)("p",{parentName:"li"},"For example:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"module.academy_lbhatestrbviews_database_ingestion[0].ingestion_database_name\n"))))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},'"--s3_ingestion_bucket_target"')," (required): The S3 location where the ingested tables should be stored"),(0,o.kt)("p",{parentName:"li"},"For example:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},'"--s3_ingestion_bucket_target" = "s3://${module.<ZONE>_zone.bucket_id}/<YOUR-DEPARTMENT-NAME>/"\n')),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"Note: ensure that your department name and folder name is all ",(0,o.kt)("strong",{parentName:"em"},"lowercase")," with ",(0,o.kt)("strong",{parentName:"em"},"words separated by hyphens"),"\ne.g. ",(0,o.kt)("inlineCode",{parentName:"em"},"housing-repairs"),".")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},'"--s3_ingestion_details_target"')," (required): The S3 location where the ingestion details should be stored "),(0,o.kt)("p",{parentName:"li"},"  ",(0,o.kt)("em",{parentName:"p"},"Note: in order for the Crawler to add your ingestion details to the Glue Catalog Database so that they can be analysed in Athena later,\nyou should set this parameter to have one additional folder level (e.g.",(0,o.kt)("inlineCode",{parentName:"em"},"ingestion-details"),") to what was set in ",(0,o.kt)("strong",{parentName:"em"},(0,o.kt)("inlineCode",{parentName:"strong"},"s3_ingestion_bucket_target"))),"."),(0,o.kt)("p",{parentName:"li"},"  For example:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},'"--s3_ingestion_details_target" = "s3://${module.<ZONE>_zone.bucket_id}/<YOUR-DEPARTMENT-NAME>/ingestion-details/"\n')),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("em",{parentName:"li"},"Note: ensure that your department name is all ",(0,o.kt)("strong",{parentName:"em"},"lowercase")," with ",(0,o.kt)("strong",{parentName:"em"},"words separated by underscores"),"\ne.g. ",(0,o.kt)("inlineCode",{parentName:"em"},"housing_repairs"),".")))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("strong",{parentName:"p"},"crawler_details"),":"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"database_name")," (required): Glue database where results are written after being crawled"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},"module.department_<YOUR_DEPARTMENT_NAME>.<S3_BUCKET_ZONE>_catalog_database_name\n")),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},"Where ",(0,o.kt)("inlineCode",{parentName:"li"},"<S3_BUCKET_ZONE>")," can be either: ",(0,o.kt)("inlineCode",{parentName:"li"},"raw")," or ",(0,o.kt)("inlineCode",{parentName:"li"},"landing"),". The same zone you wrote the data to in S3."))),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"s3_target_location")," (required): This should be the same as ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("inlineCode",{parentName:"strong"},'"--s3_ingestion_bucket_target"'))," set above")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("p",{parentName:"li"},(0,o.kt)("em",{parentName:"p"},"configuration")," (required): Set the ",(0,o.kt)("inlineCode",{parentName:"p"},"TableLevelConfiguration")," to 1 plus the number of directory levels in ",(0,o.kt)("strong",{parentName:"p"},(0,o.kt)("inlineCode",{parentName:"strong"},'"--s3_ingestion_bucket_target"'))),(0,o.kt)("p",{parentName:"li"},"For example: The value for ",(0,o.kt)("inlineCode",{parentName:"p"},"TableLevelConfiguration")," with an ",(0,o.kt)("strong",{parentName:"p"},"s3_ingestion_bucket_target")," of ",(0,o.kt)("inlineCode",{parentName:"p"},'"s3://${module.raw_zone.bucket_id}/academy/"')," will be ",(0,o.kt)("inlineCode",{parentName:"p"},"3")," "),(0,o.kt)("p",{parentName:"li"},"A complete example of ",(0,o.kt)("strong",{parentName:"p"},"crawler_details")," can be seen below:"),(0,o.kt)("pre",{parentName:"li"},(0,o.kt)("code",{parentName:"pre"},'crawler_details = {\n    database_name      = module.department_academy.raw_zone_catalog_database_name \n    s3_target_location = "s3://${module.raw_zone.bucket_id}/academy/"\n    configuration = jsonencode({\n        Version = 1.0\n        Grouping = {\n            TableLevelConfiguration = 3\n        }\n    })\n}\n')))))))),(0,o.kt)("h3",{id:"commit-your-changes-and-create-a-pull-request-for-review-by-the-data-platform-team"},"Commit your changes and create a Pull Request for review by the Data Platform team"),(0,o.kt)("p",null,"You can now submit your changes for review by the Data Platform team."),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"See ",(0,o.kt)("a",{parentName:"li",href:"../getting-set-up/using-github#committing-your-changes-to-the-data-platform-project"},"Committing changes")," section of the ",(0,o.kt)("strong",{parentName:"li"},"Using Github")," guide.\nThe Data Platform team needs to approve any changes to the code that you make, so your change won't happen automatically.\nOnce your changes have been approved and deployed, the job will run at the next scheduled time (if scheduled).")),(0,o.kt)("h3",{id:"running-the-ingestion-manually"},"Running the ingestion manually"),(0,o.kt)("p",null,"Once you have been notified that your Pull Request has been merged, you can run the ingestion manually from the AWS Console or wait until the scheduled time (if you've set one)."),(0,o.kt)("h3",{id:"example-module-block"},"Example module block"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'module "academy_lbhatestrbviews_database_ingestion" {\n    count = local.is_live_environment ? 1 : 0\n    tags  = module.tags.values\n\n    source = "../modules/database-ingestion-via-jdbc-connection"\n\n    jdbc_connection_name        = "Council Tax"\n    jdbc_connection_url         = "jdbc:sqlserver://10.120.23.22:1433;databaseName=LBHATestRBViews"\n    jdbc_connection_description = "JDBC connection to Academy Production Insights LBHATestRBViews database"\n    jdbc_connection_subnet_id   = local.subnet_ids_list[local.subnet_ids_random_index]\n    database_availability_zone  = "eu-west-2a"\n    database_secret_name        = "database-credentials/lbhatestrbviews-council-tax"\n    identifier_prefix           = local.short_identifier_prefix\n    vpc_id                      = data.aws_vpc.network.id\n}\n')))}u.isMDXComponent=!0}}]);