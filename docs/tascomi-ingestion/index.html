<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.6">
<link rel="search" type="application/opensearchdescription+xml" title="Hackney Data Platform Playbook" href="/Data-Platform-Playbook/opensearch.xml"><title data-react-helmet="true">Tascomi data ingestion | Hackney Data Platform Playbook</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://playbook.hackney.gov.uk//Data-Platform-Playbook/docs/tascomi-ingestion"><meta data-react-helmet="true" name="docsearch:language" content="en"><meta data-react-helmet="true" name="docsearch:version" content="current"><meta data-react-helmet="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Tascomi data ingestion | Hackney Data Platform Playbook"><meta data-react-helmet="true" name="description" content="Description of the ingestion and refinement pipeline for Tascomi planning data"><meta data-react-helmet="true" property="og:description" content="Description of the ingestion and refinement pipeline for Tascomi planning data"><link data-react-helmet="true" rel="shortcut icon" href="/Data-Platform-Playbook/img/favicon.png"><link data-react-helmet="true" rel="canonical" href="https://playbook.hackney.gov.uk//Data-Platform-Playbook/docs/tascomi-ingestion"><link data-react-helmet="true" rel="alternate" href="https://playbook.hackney.gov.uk//Data-Platform-Playbook/docs/tascomi-ingestion" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://playbook.hackney.gov.uk//Data-Platform-Playbook/docs/tascomi-ingestion" hreflang="x-default"><link data-react-helmet="true" rel="preconnect" href="https://BH4D9OD16A-dsn.algolia.net" crossorigin="anonymous"><link rel="stylesheet" href="/Data-Platform-Playbook/assets/css/styles.1180568a.css">
<link rel="preload" href="/Data-Platform-Playbook/assets/js/runtime~main.6f32879d.js" as="script">
<link rel="preload" href="/Data-Platform-Playbook/assets/js/main.e3e71bd3.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_1oUP">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Data-Platform-Playbook/"><img src="/Data-Platform-Playbook/img/logo-long.svg" alt="Data Platform Playbook" class="themedImage_1VuW themedImage--light_3UqQ navbar__logo"><img src="/Data-Platform-Playbook/img/logo-long.svg" alt="Data Platform Playbook" class="themedImage_1VuW themedImage--dark_hz6m navbar__logo"><b class="navbar__title">Data Platform Playbook</b></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/LBHackney-IT/data-platform-playbook" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_3J9K"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="react-toggle toggle_3Zt9 react-toggle--disabled"><div class="react-toggle-track" role="button" tabindex="-1"><div class="react-toggle-track-check"><span class="toggle_71bT">ðŸŒœ</span></div><div class="react-toggle-track-x"><span class="toggle_71bT">ðŸŒž</span></div><div class="react-toggle-thumb"></div></div><input type="checkbox" class="react-toggle-screenreader-only" aria-label="Switch between dark and light mode"></div><div class="searchBox_1Doo"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_31aa"><button class="clean-btn backToTopButton_35hR" type="button"><svg viewBox="0 0 24 24" width="28"><path d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6-6 6z" fill="currentColor"></path></svg></button><aside class="docSidebarContainer_3Kbt"><div class="sidebar_15mo"><nav class="menu thin-scrollbar menu_Bmed menuWithAnnouncementBar_2WvA"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" href="/Data-Platform-Playbook/glossary">Glossary</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">About</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Playbook</a></li><li class="theme-doc-sidebar-item-category menu__list-item"><a class="menu__link menu__link--sublist menu__link--active" href="#">Technical Documentation</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/exporting-snapshot-to-landing-zone">Exporting database snapshots to the Data Platform Landing Zone</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/import-external-files-to-landing-zone">Importing external files to the Data Platform Landing Zone</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/import-xlsx-from-g-drive">Import XLXS from G Drive</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/redshift">Redshift - Creating users, databases and exposing data from Glue</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Data-Platform-Playbook/docs/tascomi-ingestion">Tascomi data ingestion</a></li><li class="theme-doc-sidebar-item-link menu__list-item"><a class="menu__link" tabindex="0" href="/Data-Platform-Playbook/docs/vpc-peering-connection-dataplatform-and-production-apis-account">VPC Peering Connection between Data Platform and Production APIs AWS accounts</a></li></ul></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Architecture Decision</a></li><li class="theme-doc-sidebar-item-category menu__list-item menu__list-item--collapsed"><a class="menu__link menu__link--sublist" href="#">Spikes</a></li></ul></nav></div></aside><main class="docMainContainer_3ufF"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_3FnS"><div class="docItemContainer_33ec"><article><div class="tocCollapsible_1PrD theme-doc-toc-mobile tocMobile_3Hoh"><button type="button" class="clean-btn tocCollapsibleButton_2O1e">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Tascomi data ingestion</h1></header><p>This section describes how Tascomi Planning data gets ingested and refined in the data platform. The process relies on <a href="https://hackney-planning.tascomi.com/rest/v1/documentation.html?public_key=dd95bcd473f46a4325a4021d54500c7d#available-resources" target="_blank" rel="noopener noreferrer">Tascomi API</a> and is composed of the following steps:</p><ul><li>An initial full ingestion from Tascomi API (only once, happened in October 2021)</li><li>A daily call to the Tascomi API to get latest updated records (increment)</li><li>Parsing of the json data increment returned by the API</li><li>Refinement of the parsed data to recast all columns to the right data type</li><li>Creation of a full snapshot by applying the daily increment to the previous snapshot</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="details-of-individual-steps"></a>Details of individual steps<a class="hash-link" href="#details-of-individual-steps" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="1---ingestion"></a>1 - Ingestion<a class="hash-link" href="#1---ingestion" title="Direct link to heading">#</a></h3><p>This <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_api_ingestion.py" target="_blank" rel="noopener noreferrer">process</a> queries one API endpoint (e.g. the applications endpoint) and writes the data into a table of the same name. This process writes into the raw zone bucket, with the &#x27;api_response&#x27; prefix. The data is partitioned by <code>import_date</code>.</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_31ik" id="11---initial-full-ingestion"></a>1.1 - Initial full ingestion<a class="hash-link" href="#11---initial-full-ingestion" title="Direct link to heading">#</a></h4><p>This initial run imported the full Tascomi tables</p><h4><a aria-hidden="true" tabindex="-1" class="anchor anchor__h4 anchorWithStickyNavbar_31ik" id="12---daily-ingestion-of-latest-updated-records"></a>1.2 - Daily ingestion of latest updated records<a class="hash-link" href="#12---daily-ingestion-of-latest-updated-records" title="Direct link to heading">#</a></h4><p>The subsequent runs only ingest the records updated since the last import. The process relies on the <code>last_updated</code> column that is present on all Tascomi tables.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="2---daily-parsing-of-the-json-increments"></a>2 - Daily parsing of the json increments<a class="hash-link" href="#2---daily-parsing-of-the-json-increments" title="Direct link to heading">#</a></h3><p>This <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_parse_tables_increments.py" target="_blank" rel="noopener noreferrer">process</a> uses job bookmarking to only process new increments. It also uses a pushdown predicate to only load the last 5 daily prtitions (it is quicker than loading the full dataset).
It processes all tables in a loop. For each table, the large json blob containing all the fields is exploded into separate textual columns.</p><p>This process writes into the raw zone bucket, with the &#x27;planning/tascomi/parsed&#x27; prefix. The data is partitioned by <code>import_date</code>.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="3---daily-refinement-of-the-parsed-increments"></a>3 - Daily refinement of the parsed increments<a class="hash-link" href="#3---daily-refinement-of-the-parsed-increments" title="Direct link to heading">#</a></h3><p>This <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_recast_tables_increments.py" target="_blank" rel="noopener noreferrer">process</a> uses job bookmarking to only process new increments.
It processes all tables in a loop. For each table, the text columns are converted into correct data types (dates, boolean etc.). It uses a <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi-column-type-dictionary.json" target="_blank" rel="noopener noreferrer">column type dictionary</a> saved in S3 in a separate json file. This dictionary was created semi-automatically with FME (an ETL tool used in the Data and Insight team), by converting the list of columns described in the <a href="https://hackney-planning.tascomi.com/rest/v1/documentation.html?public_key=dd95bcd473f46a4325a4021d54500c7d#available-resources" target="_blank" rel="noopener noreferrer">API endpoints documentation</a>.</p><p>This process writes into the refined zone bucket, with the &#x27;planning/tascomi/increment&#x27; prefix. The data is partitioned by <code>import_date</code>.</p><h3><a aria-hidden="true" tabindex="-1" class="anchor anchor__h3 anchorWithStickyNavbar_31ik" id="4---creation-of-the-daily-snapshot"></a>4 - Creation of the daily snapshot<a class="hash-link" href="#4---creation-of-the-daily-snapshot" title="Direct link to heading">#</a></h3><p>This <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/scripts/jobs/planning/tascomi_create_daily_snapshot.py" target="_blank" rel="noopener noreferrer">process</a> combines the latest snapshot and all increments created since that day, to create a new snapshot. It uses pushdown predicate and job bookmarking to only process new increments. Like the 2 previous steps, it processes all tables in a loop. If several days increments need to be applied, the process first ensures that no duplicate records are present, by only keeping the latest updated one (for instance, if a planning application has changed status 2 times, it only keeps the record with the latest status). To apply the increments to the previous snapshot, we just replace pre-existing records with the newer version, using the unique id. A new column &#x27;snapshot_date&#x27; is created and set to the current date.</p><p>This process writes into the refined zone bucket, with the &#x27;planning/tascomi/snapshot&#x27; prefix. The data is partitioned by <code>snapshot_date</code>.</p><header><h1>Full workflow and scheduling</h1></header><p>The full workflow is defined in the <a href="https://github.com/LBHackney-IT/Data-Platform/blob/main/terraform/24-aws-glue-tascomi-data.tf" target="_blank" rel="noopener noreferrer">glue-tascomi-data terraform script</a>.
It defines a list of tables that needs updating everyday, and a list of static tables that are only updated weekly (these are the static tables like application types). The schedule is as follows:</p><ul><li>3am GMT: as many jobs as tables to update are triggered. Each job queries one API endpoint for latest updated records. That&#x27;s 25 jobs on Sundays (including static tables), about half of that on other days.</li><li>4am GMT: a crawler crawls the API results bucket<ul><li>the previous crawler triggers the <strong>parsing</strong> job and the crawling of its results</li><li>the previous crawler triggers the <strong>recasting</strong> job and the crawling of its results</li><li>the previous crawler triggers the <strong>daily snapshot creation</strong> job and the crawling of its results</li></ul></li><li>5am GMT: the API results bucket gets crawled again - this is in case the ingestion had not finished at 4am when the first crawling happened, and some tables were missed. The same sequence as above will repeat, each job being triggered by the crawler of the previous job. However, each job will usually finish early, as it is bookmarked and won&#x27;t usually find any new data to process.</li></ul><header><h1>Structure of the S3 buckets and Glue tables</h1></header><p>The data created along the process (initial full load, increments and snapshots) is stored in S3 in the raw and refined zones, with one folder per table.</p><p>The ready-for-use data is in the refined zone bucket with the prefix /planning/tascomi/snapshot. The corresponding tables in the Glue catalog are simply called applications, appeals, etc. To get the latest data, the query must refer to the snapshot_date latest partition, for example</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">select * from &quot;dataplatform-stg-tascomi-refined-zone&quot;.&quot;applications&quot; where snapshot_date = (select max(snapshot_date) from &quot;dataplatform-stg-tascomi-refined-zone&quot;.&quot;applications&quot;)</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>The refined increments are in the Refined zone Planning bucket, in the <code>increments</code> area. The tables are prefixed with <code>increment_</code>. To count the increment loaded on a specific day, you could use:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">select count(*) from &quot;dataplatform-stg-tascomi-refined-zone&quot;.&quot;increment_applications&quot; where import_date = &#x27;20211208&#x27;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>The parsed increments are in the Raw zone Planning bucket, in the <code>parsed</code> area. The tables are not prefixed, and partitioned by <code>import_date</code> with. To count the increment loaded on a specific day, you could use:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">select count(*) from &quot;dataplatform-stg-tascomi-raw-zone&quot;.&quot;applications&quot; where import_date = &#x27;20211208&#x27;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><p>The raw data returned by the API is in the Raw zone Planning bucket, in the <code>api_response</code> area. The tables are prefixed with <code>api_response_</code>, and partitioned by <code>import_date</code> with. To count the increment loaded on a specific day, you could use:</p><div class="codeBlockContainer_K1bP"><div class="codeBlockContent_hGly"><pre tabindex="0" class="prism-code language-undefined codeBlock_23N8 thin-scrollbar" style="color:#bfc7d5;background-color:#292d3e"><code class="codeBlockLines_39YC"><span class="token-line" style="color:#bfc7d5"><span class="token plain">select count(*) from &quot;dataplatform-stg-tascomi-raw-zone&quot;.&quot;api_response_applications&quot; where import_date = &#x27;20211208&#x27;</span></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_Ue-o clean-btn">Copy</button></div></div><header><h1>How to reset Tascomi data</h1></header><p>If you suspect a problem in the increments or snapshots, you can delete and recreate them in their respective buckets.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="reset-the-ingested-increments"></a>Reset the ingested increments:<a class="hash-link" href="#reset-the-ingested-increments" title="Direct link to heading">#</a></h2><ul><li>In S3 raw zone &#x27;api<em>response&#x27; bucket, in each table repository, delete the data up to the last date you want to keep. _Do not delete the initial full load!</em></li><li>Run the api_response crawler</li><li>Run the ingestion job</li><li>Run the api_response crawler again.</li></ul><p>As a result you should see in S3 a new partition with today&#x27;s date. It contains all records updated since the last day you kept in the bucket.</p><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="reset-the-parsed-increments"></a>Reset the parsed increments:<a class="hash-link" href="#reset-the-parsed-increments" title="Direct link to heading">#</a></h2><ul><li>In S3 raw zone, empty the &#x27;parsed&#x27; bucket</li><li>Reset the job bookmark (In Glue, &gt; job view &gt; select the job and click on actions)</li><li>Remove the pushdown predicate: open the job script and edit the line that sets the pushdown predicae to 0 days, then save:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;import_date&#x27;, daysBuffer=0)</code></p><ul><li>Run the job</li><li>Set back the pushdown predicate to its initial value, then save the script:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;import_date&#x27;, daysBuffer=5)</code></p><ul><li>Run the parsed bucket crawler</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="reset-the-refined-increments"></a>Reset the refined increments:<a class="hash-link" href="#reset-the-refined-increments" title="Direct link to heading">#</a></h2><ul><li>In S3 refined zone, empty the &#x27;increments&#x27; bucket</li><li>Reset the job bookmark (In Glue, &gt; job view &gt; select the job and click on actions)</li><li>Remove the pushdown predicate: open the job script and edit the line that sets the pushdown predicae to 0 days, then save:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;import_date&#x27;, daysBuffer=0)</code></p><ul><li>Run the job</li><li>Set back the pushdown predicate to its initial value, then save:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;import_date&#x27;, daysBuffer=5)</code></p><ul><li>Run the refined increment crawler</li></ul><h2><a aria-hidden="true" tabindex="-1" class="anchor anchor__h2 anchorWithStickyNavbar_31ik" id="reset-the-refined-snapshot"></a>Reset the refined snapshot:<a class="hash-link" href="#reset-the-refined-snapshot" title="Direct link to heading">#</a></h2><ul><li>In S3 refined zone, empty the &#x27;snapshot&#x27; bucket</li><li>Delete all the snapshot tables in the Glue catalogue</li><li>Reset the job bookmark (In Glue, &gt; job view &gt; select the job and click on actions)</li><li>Remove the pushdown predicate: open the job script and edit the line that sets the pushdown predicae to 0 days, then save:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;snapshot_date&#x27;, daysBuffer=0)</code></p><ul><li>Run the job</li><li>Set back the pushdown predicate to its initial value:</li></ul><p><code>pushdown_predicate = create_pushdown_predicate(partitionDateColumn=&#x27;snapshot_date&#x27;, daysBuffer=5)</code></p><ul><li>Run the refined snapshot crawler.</li></ul><p>As a resut you should only have today&#x27;s snapshot in the snapshot bucket.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_2ga9 padding--none margin-left--sm"><li class="tag_11ep"><a class="tag_1Okp tagRegular_3MiF" href="/Data-Platform-Playbook/tags/playbook">playbook</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/LBHackney-IT/data-platform-playbook/edit/master/docs/docs/tascomi-ingestion.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_2_ui" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_13-_"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/Data-Platform-Playbook/docs/redshift"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Â« Redshift - Creating users, databases and exposing data from Glue</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/Data-Platform-Playbook/docs/vpc-peering-connection-dataplatform-and-production-apis-account"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">VPC Peering Connection between Data Platform and Production APIs AWS accounts Â»</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_35-E thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#details-of-individual-steps" class="table-of-contents__link">Details of individual steps</a><ul><li><a href="#1---ingestion" class="table-of-contents__link">1 - Ingestion</a></li><li><a href="#2---daily-parsing-of-the-json-increments" class="table-of-contents__link">2 - Daily parsing of the json increments</a></li><li><a href="#3---daily-refinement-of-the-parsed-increments" class="table-of-contents__link">3 - Daily refinement of the parsed increments</a></li><li><a href="#4---creation-of-the-daily-snapshot" class="table-of-contents__link">4 - Creation of the daily snapshot</a></li></ul></li><li><a href="#reset-the-ingested-increments" class="table-of-contents__link">Reset the ingested increments:</a></li><li><a href="#reset-the-parsed-increments" class="table-of-contents__link">Reset the parsed increments:</a></li><li><a href="#reset-the-refined-increments" class="table-of-contents__link">Reset the refined increments:</a></li><li><a href="#reset-the-refined-snapshot" class="table-of-contents__link">Reset the refined snapshot:</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Made by HackIT.</div></div></div></footer></div>
<script src="/Data-Platform-Playbook/assets/js/runtime~main.6f32879d.js"></script>
<script src="/Data-Platform-Playbook/assets/js/main.e3e71bd3.js"></script>
</body>
</html>